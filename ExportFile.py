import requests
import json
from bs4 import BeautifulSoup
import os, time, re, concurrent.futures
from datetime import datetime
import pandas as pd

# ========== C√ÅC H√ÄM EXPORT ==========

def export_dep_report(session_id, store_cd, start_date, end_date):
    url = "https://ss.circlek.com.vn/scmaster/a/classifiedSaleReport/export"
    payload = {
        "regionCd": "", "cityCd": "", "districtCd": "", "storeCd": store_cd,
        "am": "", "startDate": start_date, "endDate": end_date,
        "depCd": "", "categoryCd": "", "subCategoryCd": "",
        "pmaCd": "", "page": 1, "rows": 10
    }
    headers = {
        "accept": "*/*", "content-type": "application/x-www-form-urlencoded; charset=UTF-8",
        "cookie": f"SESSION={session_id}",
        "referer": "https://ss.circlek.com.vn/scmaster/a/classifiedSaleReport",
        "user-agent": "Mozilla/5.0"
    }
    resp = requests.post(url, data={"searchJson": json.dumps(payload, ensure_ascii=False)}, headers=headers)
    soup = BeautifulSoup(resp.content, "html.parser")
    tag = soup.find("input", id="expKey")
    return tag["value"] if tag else None


def export_sell_day_report(session_id, store_cd, start_date, end_date, include_service="20", type_date="1"):
    url = "https://ss.circlek.com.vn/scmaster/a/sellDayReport/export"
    payload = {
        "regionCd": "", "cityCd": "", "districtCd": "", "storeCd": store_cd,
        "am": "", "effectiveStartDate": start_date, "effectiveEndDate": end_date,
        "page": 1, "rows": 10, "includeService": include_service, "typeDate": type_date
    }
    headers = {
        "accept": "*/*", "content-type": "application/x-www-form-urlencoded; charset=UTF-8",
        "cookie": f"SESSION={session_id}",
        "referer": "https://ss.circlek.com.vn/scmaster/a/sellDayReport",
        "user-agent": "Mozilla/5.0"
    }
    resp = requests.post(url, data={"searchJson": json.dumps(payload, ensure_ascii=False)}, headers=headers)
    soup = BeautifulSoup(resp.content, "html.parser")
    tag = soup.find("input", id="expKey")
    return tag["value"] if tag else None


def export_sell_item_report(session_id, store_cd, start_date, end_date, department_cd=None, category_cd=None, subCategory_cd=None, barcode=None, articleName=None):
    import urllib.parse
    url = "https://ss.circlek.com.vn/scmaster/a/GoodsSaleReport/export"
    payload = {
        "regionCd": "", "cityCd": "", "districtCd": "", "storeCd": store_cd,
        "am": "", "depCd": "", "pmaCd": department_cd, "categoryCd": category_cd,
        "subCategoryCd": subCategory_cd, "startDate": start_date, "endDate": end_date,
        "barcode": barcode, "articleName": articleName, "page": 1, "rows": 10
    }
    full_url = f"{url}?{urllib.parse.urlencode({'searchJson': json.dumps(payload, ensure_ascii=False)})}"
    headers = {
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "cookie": f"SESSION={session_id}",
        "user-agent": "Mozilla/5.0"
    }
    resp = requests.get(full_url, headers=headers)
    soup = BeautifulSoup(resp.content, "html.parser")
    tag = soup.find("input", id="expKey")
    return tag["value"] if tag else None


# ========== CHECK + DOWNLOAD ==========

def exp_check(session_id, exp_key, timeout=99):
    """Ki·ªÉm tra export c√≥ s·∫µn s√†ng trong t·ªëi ƒëa `timeout` gi√¢y"""
    url = "https://ss.circlek.com.vn/scmaster/a/expcheck"
    headers = {
        "accept": "application/json, text/javascript, */*; q=0.01",
        "content-type": "application/x-www-form-urlencoded; charset=UTF-8",
        "cookie": f"SESSION={session_id}",
        "x-requested-with": "XMLHttpRequest",
        "user-agent": "Mozilla/5.0"
    }
    start = time.time()
    while time.time() - start < timeout:
        try:
            resp = requests.post(url, data={"key": exp_key}, headers=headers, timeout=10)
            data = resp.json()
            if data.get("status") == 2 and "filename" in data:
                return True
        except Exception:
            pass
        time.sleep(2)
    return False


def download_exported_file(exp_key_value, session_id, folder_path=None, filename=None):
    import os, re, requests

    download_url = f"https://ss.circlek.com.vn/scmaster/a/export/{exp_key_value}"
    headers = {"cookie": f"SESSION={session_id}"}
    response = requests.get(download_url, headers=headers)

    if response.status_code == 200:
        # üîç L·∫•y t√™n t·ª´ server
        server_filename = None
        content_disposition = response.headers.get("content-disposition", "")
        match = re.search(r'filename="?([^"]+)"?', content_disposition)
        if match:
            server_filename = match.group(1)
        
        # N·∫øu server_filename c√≥ ƒëu√¥i .xlsx th√¨ b·ªè ƒëu√¥i ƒë√≥ ƒë·ªÉ n·ªëi g·ªçn h∆°n
        if server_filename and server_filename.lower().endswith(".xlsx"):
            server_filename = server_filename[:-5]

        # ‚úÖ N·∫øu c√≥ filename truy·ªÅn v√†o ‚Üí gh√©p c·∫£ 2
        if filename:
            final_name = f"{filename}__{server_filename or exp_key_value}.xlsx"
        else:
            final_name = f"{server_filename or exp_key_value}.xlsx"

        save_path = os.path.join(folder_path, final_name)

        with open(save_path, "wb") as f:
            f.write(response.content)

        return save_path

    else:
        print(f"‚ö†Ô∏è L·ªói t·∫£i file (status {response.status_code})")
        return None



# ========== G·ªòP FILE NHANH B·∫∞NG PANDAS + SONG SONG ==========

def merge_excel_fast_parallel(saved_files, output_path, header_row=2, max_workers=20):
    """G·ªôp nhanh c√°c file Excel b·∫±ng pandas (ƒëa lu·ªìng ƒë·ªçc song song)"""
    t0 = time.time()

    def read_file(path):
        try:
            df = pd.read_excel(path, header=header_row, engine="openpyxl")
            return df
        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc {path}: {e}")
            return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:
        dfs = list(ex.map(read_file, saved_files))

    dfs = [d for d in dfs if d is not None]
    if not dfs:
        print("‚ö†Ô∏è Kh√¥ng c√≥ file h·ª£p l·ªá ƒë·ªÉ g·ªôp!")
        return

    merged_df = pd.concat(dfs, ignore_index=True)
    merged_df.to_excel(output_path, index=False, engine="openpyxl")

    print(f"‚úÖ ƒê√£ g·ªôp {len(saved_files)} file ({len(merged_df)} d√≤ng)")
    print(f"‚ö° Th·ªùi gian g·ªôp: {round(time.time() - t0, 2)}s")


# ========== QU·∫¢N L√ù CH√çNH ==========

def group_craw_data(
    session_id, store_cd_group, start_date, end_date, type_report,
    folder_path, department_cd=None, category_cd=None,
    subCategory_cd=None, barcode=None, articleName=None,
    merge_files=True,
    format_export_sell_item_report=False,
    format_export_dep_report=False,
    format_export_sell_day_report=False
):
    import os, re, concurrent.futures
    from datetime import datetime

    print(f"\nüïí {datetime.now().strftime('%H:%M:%S')} | B·∫ÆT ƒê·∫¶U {type_report}")

    # üîπ T·ª± ƒë·ªông x√°c ƒë·ªãnh th∆∞ m·ª•c con theo lo·∫°i report
    if type_report == "export_sell_item_report":
        folder_path = os.path.join(folder_path, "Item Sales Data")
    elif type_report == "export_dep_report":
        folder_path = os.path.join(folder_path, "Department Data")
    elif type_report == "export_sell_day_report":
        folder_path = os.path.join(folder_path, "Sales Data")
    else:
        folder_path = os.path.join(folder_path, "Other Reports")

    os.makedirs(folder_path, exist_ok=True)  # ƒë·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i

    exp_key_map = {}

    # 1Ô∏è‚É£ L·∫•y exp_key tu·∫ßn t·ª±
    for store_cd in store_cd_group:
        try:
            if type_report == "export_sell_item_report":
                exp_key = export_sell_item_report(
                    session_id, store_cd, start_date, end_date,
                    department_cd, category_cd, subCategory_cd,
                    barcode, articleName
                )
            elif type_report == "export_sell_day_report":
                exp_key = export_sell_day_report(session_id, store_cd, start_date, end_date)
            elif type_report == "export_dep_report":
                exp_key = export_dep_report(session_id, store_cd, start_date, end_date)
            else:
                exp_key = None

            print(f"‚Üí {store_cd}: exp_key = {exp_key}")
            exp_key_map[store_cd] = exp_key
        except Exception as e:
            print(f"‚ùå {store_cd}: l·ªói l·∫•y exp_key ({e})")

    # 2Ô∏è‚É£ ƒêa lu·ªìng exp_check + download
    def process_download(store_cd, exp_key):
        if not exp_key:
            return f"‚ö†Ô∏è {store_cd}: Kh√¥ng c√≥ exp_key"
        if exp_check(session_id, exp_key):
            save_path = download_exported_file(exp_key, session_id, folder_path, store_cd)
            return f"‚úÖ {store_cd}: T·∫£i th√†nh c√¥ng {save_path}" if save_path else f"‚ö†Ô∏è {store_cd}: Kh√¥ng t·∫£i ƒë∆∞·ª£c file"
        else:
            return f"‚ö†Ô∏è {store_cd}: H·∫øt h·∫°n ch·ªù export"

    saved_files = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=min(20, len(store_cd_group))) as executor:
        futures = {executor.submit(process_download, s, k): s for s, k in exp_key_map.items()}
        for fut in concurrent.futures.as_completed(futures):
            result = fut.result()
            print(result)
            if "T·∫£i th√†nh c√¥ng" in result:
                path_match = re.search(r" (C:.+\.xlsx)", result)
                if path_match:
                    saved_files.append(path_match.group(1))

    # 3Ô∏è‚É£ G·ªôp file nhanh + format n·∫øu c·∫ßn
    if merge_files and saved_files:
        try:
            merged_filename = os.path.join(
                folder_path, f"GROUP_MS.MAIPHUONG_{type_report}_{start_date}_{end_date}.xlsx"
            )
            merge_excel_fast_parallel(saved_files, merged_filename)

            # üß© G·ªçi format t∆∞∆°ng ·ª©ng
            if type_report == "export_sell_item_report" and format_export_sell_item_report:
                format_sell_item_report(merged_filename)

            elif type_report == "export_dep_report" and format_export_dep_report:
                format_dep_report(merged_filename)

            elif type_report == "export_sell_day_report" and format_export_sell_day_report:
                format_sell_day_report(merged_filename)

        except Exception as e:
            print(f"‚ùå L·ªói khi g·ªôp/format file: {e}")

    print(f"üèÅ {datetime.now().strftime('%H:%M:%S')} | HO√ÄN TH√ÄNH {type_report}")


def format_sell_item_report(filepath):
    print(f"üé® Format file SELL ITEM REPORT: {filepath}")
    import pandas as pd

    # ƒê·ªçc file Excel
    df = pd.read_excel(filepath)

    # 1Ô∏è‚É£ Sort theo "Store No."
    if "Store No." in df.columns:
        df["Store No."] = df["Store No."].astype(str)
        df = df.sort_values(by="Store No.", ascending=True)
        print("‚úÖ ƒê√£ sort theo 'Store No.' (A ‚Üí Z)")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt 'Store No.' ƒë·ªÉ sort")

    # 2Ô∏è‚É£ X√≥a c√°c d√≤ng ch·ª©a "Total item:" trong c·ªôt Department
    if "Department" in df.columns:
        before_count = len(df)
        # Remove rows that contain 'Total item' (partial match)
        df = df[~df["Department"].astype(str).str.contains("Total item", case=False, na=False)]
        # Also remove rows where Department equals '19 Services' (exact match after strip)
        df = df[df["Department"].astype(str).str.strip() != "19 Services"]
        after_count = len(df)
        removed = before_count - after_count
        print(f"üßπ ƒê√£ xo√° {removed} d√≤ng c√≥ 'Total item:' ho·∫∑c '19 Services' trong c·ªôt Department")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt 'Department' ƒë·ªÉ l·ªçc")

    # 3Ô∏è‚É£ X√≥a c·ªôt "NO." n·∫øu t·ªìn t·∫°i
    if "NO." in df.columns:
        df = df.drop(columns=["NO."])
        print("üóëÔ∏è ƒê√£ xo√° c·ªôt 'NO.'")
    else:
        print("‚ö†Ô∏è Kh√¥ng c√≥ c·ªôt 'NO.' ƒë·ªÉ xo√°")

    # 4Ô∏è‚É£ Ghi ƒë√® l·∫°i file g·ªëc
    df.to_excel(filepath, index=False)
    print(f"üíæ ƒê√£ ghi ƒë√® file sau khi format: {filepath}")



def format_dep_report(filepath):
    import pandas as pd

    print(f"üé® Format file DEP REPORT: {filepath}")

    # ƒê·ªçc file Excel
    df = pd.read_excel(filepath)

    # üßπ X√≥a c·ªôt "NO." n·∫øu c√≥
    if "NO" in df.columns:
        df = df.drop(columns=["NO"])
        print("üßæ ƒê√£ x√≥a c·ªôt 'NO'")

    # üîΩ Sort theo 'Store No.' n·∫øu c√≥
    if "Store No." in df.columns:
        df = df.sort_values(by="Store No.", ascending=True)
        print("‚úÖ ƒê√£ sort theo 'Store No.' (A ‚Üí Z)")

    # ‚ùå X√≥a c√°c d√≤ng c√≥ Department = "19 Services"
    if "Department" in df.columns:
        before = len(df)
        df = df[df["Department"].astype(str).str.strip() != "19 Services"]
        after = len(df)
        print(f"üöÆ ƒê√£ x√≥a {before - after} d√≤ng c√≥ 'Department' = '19 Services'")

    # üíæ Ghi ƒë√® l·∫°i file
    df.to_excel(filepath, index=False)
    print("üíæ ƒê√£ l∆∞u file sau khi format xong.")

def format_sell_day_report(filepath):
    import pandas as pd

    print(f"üìÖ Format file SELL DAY REPORT: {filepath}")

    # ƒê·ªçc d·ªØ li·ªáu
    df = pd.read_excel(filepath)

    # üßπ X√≥a c·ªôt "NO." n·∫øu c√≥
    if "NO." in df.columns:
        df = df.drop(columns=["NO."])
        print("üßæ ƒê√£ x√≥a c·ªôt 'NO.'")

    # 1Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu Store No.
    if "Store No." not in df.columns:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt 'Store No.'")
        return

    # L∆∞u c·ªôt g·ªëc ƒë·ªÉ tham chi·∫øu
    df["__Store_Group__"] = df["Store No."].ffill()  # Lan gi√° tr·ªã Store No. xu·ªëng c√°c d√≤ng con

    # 2Ô∏è‚É£ Sort theo nh√≥m Store No. (v√† gi·ªØ nguy√™n th·ª© t·ª± trong nh√≥m)
    df["_sort_order"] = df.index  # gi·ªØ v·ªã tr√≠ g·ªëc
    df = df.sort_values(by=["__Store_Group__", "_sort_order"], ascending=[True, True])
    df = df.drop(columns=["_sort_order", "__Store_Group__"])

    # 3Ô∏è‚É£ Format c·ªôt Date n·∫øu c√≥
    if "Date" in df.columns:
        df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.strftime("%Y-%m-%d")

    # 4Ô∏è‚É£ Ghi l·∫°i file
    df.to_excel(filepath, index=False)
    print("‚úÖ ƒê√£ sort theo 'Store No.' (A ‚Üí Z) v√† gi·ªØ nguy√™n nh√≥m d·ªØ li·ªáu g·ªëc.")



def format_sell_single_item_report(filepath):
    print(f"üé® Format file SELL ITEM REPORT: {filepath}")

    # 1Ô∏è‚É£ ƒê·ªçc Excel, b·ªè 2 d√≤ng ƒë·∫ßu, l·∫•y d√≤ng 3 l√†m header
    df = pd.read_excel(filepath, header=2)
    print("‚úÖ ƒê√£ l·∫•y d√≤ng 3 l√†m header (b·ªè 2 d√≤ng ƒë·∫ßu)")

    # 2Ô∏è‚É£ Danh s√°ch c√°c c·ªôt c·∫ßn xo√°
    cols_to_remove = [
        "NO.",
        "Store No.",
        "Store Name",
        # "Sale Date",
        "Top Department",
        "Selling Price",
        "Area Manager ID",
        "Area Manager Name",
    ]

    # 3Ô∏è‚É£ Xo√° c√°c c·ªôt t·ªìn t·∫°i trong danh s√°ch
    existing_cols = [c for c in cols_to_remove if c in df.columns]
    if existing_cols:
        df = df.drop(columns=existing_cols)
        print(f"üóëÔ∏è ƒê√£ xo√° c√°c c·ªôt: {', '.join(existing_cols)}")

    # 4Ô∏è‚É£ X√≥a c√°c d√≤ng c√≥ gi√° tr·ªã "19 Services" trong c·ªôt Department
    if "Department" in df.columns:
        before = len(df)
        df = df[~df["Department"].astype(str).str.contains("19 Services|Total item:", case=False, na=False)]
        removed = before - len(df)
        print(f"üßπ ƒê√£ xo√° {removed} d√≤ng c√≥ '19 Services' trong c·ªôt Department")

    # 5Ô∏è‚É£ Ghi ƒë√® l·∫°i file g·ªëc
    df.to_excel(filepath, index=False)
    print(f"üíæ ƒê√£ ghi ƒë√® file sau khi format: {filepath}")

    # 6Ô∏è‚É£ Tr·∫£ v·ªÅ JSON (convert DataFrame th√†nh list of dict)
    data_json = df.to_dict(orient="records")
    return data_json


def item_sell_by_store(start_date, end_date, department_cd, category_cd, subCategory_cd):
    from loginCirclek import get_session_token
    from login_utils import get_login_info
    BASE_PATH = r'C:\Users\SG0xxx-Tablet\Documents\SM\TOOL BCS\Order\order-backend'
    ITEM_FOLDER = os.path.join(BASE_PATH, 'Data', 'Item')

    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
    os.makedirs(ITEM_FOLDER, exist_ok=True)

    session_id = get_session_token()
    store_cd = get_login_info("store_cd")
    exp_key = export_sell_item_report(session_id, store_cd, start_date, end_date, department_cd, category_cd=category_cd, subCategory_cd=subCategory_cd)
    if exp_check(session_id, exp_key):
        print(exp_key)

        save_path = download_exported_file(exp_key, session_id, ITEM_FOLDER, store_cd)

        # üîß Format Excel v√† l·∫•y JSON
        data_json = format_sell_single_item_report(save_path)

        # # üíæ Ghi JSON ra file
        # json_filename = f"{store_cd}_SELL_ITEM_{start_date}_{end_date}.json"
        # json_path = os.path.join(ITEM_FOLDER, json_filename)
        # with open(json_path, "w", encoding="utf-8") as f:
        #     json.dump(data_json, f, ensure_ascii=False, indent=2)

        # print(f"‚úÖ ƒê√£ l∆∞u file JSON: {json_path}")

        # print(data_json)
        return data_json
    else:
        print("‚ùå Kh√¥ng th·ªÉ export file SELL ITEM REPORT")
        return []
# print(item_sell_by_store("20251031", "20251031", "", "", ""))
# from loginCirclek import get_session_token
# from login_utils import get_login_info
# BASE_PATH = r'C:\Users\SG0xxx-Tablet\Documents\SM\TOOL BCS\Order\order-backend'
# ITEM_FOLDER = os.path.join(BASE_PATH, 'Data', 'Item')
# session_id = get_session_token()
# store_cd_group = get_login_info("store_cd_group")
# store_cd = get_login_info("store_cd")
# start_date = "20251101"
# end_date = "20251127"
# group_craw_data(
#     session_id=session_id,
#     store_cd_group=store_cd_group,
#     start_date=start_date,
#     end_date=end_date,
#     type_report="export_sell_day_report",
#     folder_path=ITEM_FOLDER,
#     department_cd="",      # t√πy theo c·∫•u tr√∫c h·ªá th·ªëng
#     category_cd=None,
#     subCategory_cd=None,
#     barcode="",
#     articleName="",
#     merge_files=True,  # ƒê·∫∑t False n·∫øu kh√¥ng mu·ªën g·ªôp file
#     format_export_sell_item_report=True,
#     format_export_dep_report=True,
#     format_export_sell_day_report=True
# )